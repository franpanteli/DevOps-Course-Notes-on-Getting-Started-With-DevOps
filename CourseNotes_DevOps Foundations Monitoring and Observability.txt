Course Title: DevOps Foundations: Monitoring and Observability

Description: Monitoring is a key practice area of modern operations. In this course, explore techniques and tools for monitoring from a DevOps mindset. Instructors Ernest Mueller and Peco Karayanev spell out what monitoring is, what's unique about the DevOps approach to monitoring, and how to model your system so monitoring makes sense in context. Next, they examine the different types of monitoring instrumentation, including how to implement synthetic monitoring, end user monitoring, system monitoring, and network monitoring. They also cover best practices for architecting systems for observability and share how to overcome common obstacles.


***********************************************
Chapter: Introduction
***********************************************


-----------------------------------------------
Video: Welcome
-----------------------------------------------
Note Time:         Note Text:                     

0:00:15            -> devops -> developers and operations collaborating to deliver software at high speeds to the users 

0:01:15            -> monitoring and observability from a devops perspective -> kinds of monitoring, best practices and road blocks 


-----------------------------------------------
Video: What you should know
-----------------------------------------------
Note Time:         Note Text:                     

0:00:38            -> prerequisites -> devops fundamentals course (infrastructure automation, continuous delivery and reliability engineering). This course is the monitoring part of reliability engineering 

0:00:55            -> IT / development / operations -> chapters 1-3 for monitoring 


***********************************************
Chapter: 1. Monitoring Basics
***********************************************


-----------------------------------------------
Video: What is monitoring?
-----------------------------------------------
Note Time:         Note Text:                     

0:00:29            -> monitoring -> being logically rigorous. To observe and check the quality of something (part of the service / activity, monitoring targets) over time 

0:01:23            -> monitoring to better serve the business -> objectives are - problem detection, troubleshooting, reporting and improvement 

0:02:31            -> what we monitor - different metrics for services. Picking the right metric is important, and depends on demand, workload (availability, performance, faults/ errors), resources (technical metrics) and business metrics 

0:03:53            -> so we're picking a metric and continuously monitoring it. Monitoring metrics can be done with tools which give alerts etc. Developing a monitoring system when there are too many failures -> tools and knowing how to use them 


-----------------------------------------------
Video: Observability in a DevOps world
-----------------------------------------------
Note Time:         Note Text:                     

0:00:31            -> observability -> this is a property of a system from control theory, and is defined as a measure of how well the internal states of a system can be inferred from its external outputs. It's, for a given metric, if we monitor that metric, then how well is it showing us the status of the internal system 

0:00:50            -> by looking at the metric, how well can we tell what the system is donig 

0:01:25            -> it depends on the outputs and the tooling used to observe it (you need the right tools and metrics - rather than just monitoring a lot of data, you want the data which is relevant -> and then data which is observable is data which can be used to monitor the system state) 

0:02:10            -> creating logs and metrics and being able to decompose them depending on their function. Observable devops monitoring tools -> these should have self-service / have smart defaults and should be configurable by those using it. A tools which can find services, instrument their outputs and be configured via the same calls and builds 

0:02:42            -> observably monitoring system dynamics -> systems change state, so monitoring tools need to be able to adapt to them dynamically under name, speed and scale 

0:03:10            -> monitoring should be collaborative -> multiple people should be able to share different reports and alerts provided from the monitoring tools. This provides observability 

0:03:43            -> holistic monitoring -> you need to be able to observe the behaviour of the system as a whole 

0:03:58            -> change-aware -> observable monitoring should allow us to monitor sudden changes in the system 

0:04:24            -> observable monitoring - automatable -> real-time analysis so it can turn observations into action without always requiring manual intervention. Monitoring is an action, and observability is a quality of a system 

0:04:40            -> the overall monitoring stack, not the individual components 


-----------------------------------------------
Video: Monitoring: What does it all mean?
-----------------------------------------------
Note Time:         Note Text:                     

0:00:23            -> monitoring is a data science problem -> using engineering definitions for monitoring frameworks 

0:00:31            -> vendors for monitoring tools can use software terminology in a marketing context but these have academic definitions which are defined by computer science 

0:01:06            -> instrumentation <- how monitoring tools get their data. Instrumenting the system is applying monitoring tools to the system -> the monitoring tools are the instruments -> instrumentation as the verb 

0:01:30            -> knowing how the tool instruments so you know what it shows and doesn't show you. Most tools take samples over a unit of time -> sampling frequency / resolution 

0:02:24            -> the monitoring system works from data which is sampled -> this needs to be done frequently enough or there is a risk of missing trends. A series is a metric which is recorded over time -> it must have a timestamp of a value and other metadata (e.g in the form of tag) 

0:02:42            -> we can record metrics, events and diagnostics. Events -> when a defined set of conditions is met (timestamps and payloads). This is in comparison to metrics, which are data we measure at intervals 

0:03:04            -> the third measurement type is diagnostic measurement -> e.g x-rays 

0:03:08            -> monitoring is a data science problem -> measuring data about the performance of the system and drawing conclusions from it to better the software development pipeline 

0:03:08            -> understanding metrics, how they are instrumented and what their frequency is 


-----------------------------------------------
Video: Monitoring: Math is required
-----------------------------------------------
Note Time:         Note Text:                     

0:00:15            -> understanding metrics and what they mean <- interpreting metrics 

0:00:41            -> to understand different metrics, we need to know how they relate to each other 

0:01:57            -> factors which determine the usefulness of the metrics -> sampling (downsampling -> tools throw away samples -> the amount of data / sample size we collect -> the more data collected the higher the cost). Using smaller sample sizes can cause trends to be missed 

0:02:36            -> timelines -> where the timestamp on the metric comes from -> clock skew between in and other systems. Timestamps -> these can vary according to time zones and the systems which are being used 

0:02:47            -> to ensure time metrics are measured accurately -> precision - how a metric is sampled, the frequency it is at and the time its timestamp represents 

0:03:33            -> statistical analysis -> this can be automated. Comparing a metric over time looking at the baseline and deviation / looking at correlations 


-----------------------------------------------
Video: Modeling your system
-----------------------------------------------
Note Time:         Note Text:                     

0:00:00            -> modelling monitoring systems -> complex systems can involve many parts which need monitoring. A system is only as weak as its weakest link -> we need to look at the entire system to determine which part of it is the weakest (an integrated systems monitoring strategy) 

0:00:00            -> using statistics to monitor metrics can mitigate against human error when interpreting data 

0:00:50            -> conceptual models can be used to model complex systems -> e.g the USE model (utilisation - percentage of time spent servicing work, saturation - work that can’t be services, e - error event counts) 

0:01:30            -> queuing work in complex systems -> use metrics can expose a shortage of resources where the system is more under strain when monitoring it 

0:02:08            -> RED model <-  (r - request rate, e - errors, d - duration) 

0:02:48            -> DWR <-  (d - demands request for work on a given system / requests, w - workload - execution of all tasks needed to serve the demand, r - resources - the physical / logical resources of the system via machine and software resources, the number of pulls etc) 

0:03:14            -> demand is the intake, workload is the output and resources are the engine of the system 

0:03:46            -> it’s about the balance of the demand, workload and resources -> it’s like supply and demand, except supply is in terms of hardware (resources), software (workload) - and then we have demand 


***********************************************
Chapter: 2. Types of Monitoring Instrumentation
***********************************************


-----------------------------------------------
Video: Our monitoring system
-----------------------------------------------
Note Time:         Note Text:                     

0:00:34            -> pet clinic app example (a JS app which allows us to setup vet appointments). This uses an SQL database and docker image 

0:00:48            -> to pull the project and use it differently, there is another git repo 


-----------------------------------------------
Video: Synthetic monitoring: Is it up?
-----------------------------------------------
Note Time:         Note Text:                     

0:00:18            -> he's inspecting the functions of the app -> it's a web application in chrome and there is a list of the different pet owners 

0:01:00            -> synthetic monitoring <- we need monitoring to tell us if the application is working for the users. Having a synthetic check being applied to applications at constant intervals -> e.g checking if the web app is working properly through various metrics 

0:01:16            -> some apps allow us to parse the output of the application. There are paid synthetic monitoring services -> if you think of ethical hacking as paying someone to hack into the system to see how secure it is, you can think of these monitoring services as setting up clients on the application to monitor how well it works for the desired use case 

0:01:37            -> to check if this works, you would set up an account as a draft customer and test the functionality of the web app to see how well it is working 

0:02:15            -> you can measure performance when using monitoring from several different countries 

0:02:52            -> monitoring can use resources, especially with high frequency monitoring 

0:03:35            -> monitoring can use too many resources if done too frequently 

0:04:01            -> sampling rate -> monitoring can be done using SaaS 

0:04:33            -> monitoring and testing      

0:05:03            -> using synthetic transactions to monitor the system for performance issues from specific geolocations 


-----------------------------------------------
Video: Synthetic monitoring in action
-----------------------------------------------
Note Time:         Note Text:                     

0:00:36            -> pingdom monitors -> he's online, pingdom is a website you can make an account on 

0:02:29            -> he's on the pingdom webpage and is making an uptime check -> this involves entering a port and protocol. There is a sample rate it collects data for monitoring at a certain rate, and he has also created a check 

0:03:23            -> in an example with more data -> there is an uptime report (it's a series of graphs showing the performance of the software). There is also an individual test result log -> a pet store monitor 

0:04:18            -> using pingdom and data dog together 

0:04:22            -> there is a test which emails the account owner when there is a failure -> it can also be integrated with teams. I.e pingdom -> notify me if there is a system failure 

0:04:38            -> if there are changes to the website then the monitoring will break. Site changes need to be coordinated with monitoring changes 

0:04:52            -> if the site is only inaccessible from certain network locations, the test may go off intermittently 

0:05:19            -> for some webpages the monitoring tests may look like the page is offline if it can't be accessed from certain locations, the solution to this is to monitor the test for certain locations 

0:06:00            -> you can also monitor the DNS from several different locations. Monitoring services can have outages -> and they have public status pages to see if anything is wrong with their servers (false positives etc) 

0:06:23            -> there is also transactional monitoring available 


-----------------------------------------------
Video: End user monitoring: What do users see?
-----------------------------------------------
Note Time:         Note Text:                     

0:00:16            -> servers and apps are up -> real user experiences vary by geolocation, browser and by the input variation from the users 

0:00:42            -> the longer the webpage takes to load, the more users click off the pages -> this is a finding from data science 

0:01:44            -> real user vs synthetic monitoring -> one is from simulated users / deliberately created accounts for testing the site and one is from actual users. You use a combination of real user data and data from synthetic testing -> e.g for identifying which locations the webpage needs adapting for 

0:02:03            -> global heatmaps -> a map of the world with different colours on it 

0:02:24            -> instrumentation options -> instrumentation options, web access logs, network analysis, mobile instrumentation, browser injection and desktop instrumentation 

0:02:43            -> metadata is limited to IP. Web access logs only tell you about the page delivery -> there are limits to which data can be collected 

0:03:27            -> network analysis using a third party monitoring tool -> you can test a hypothesis about the functioning of the apps using data gathering and monitoring 

0:03:53            -> usage data is sent from apps to data analytics engines -> these provide different information (e.g the battery / crash rate etc) 

0:03:54            -> usage data is sent from apps to data analytics engines -> these provide different information (e.g the battery / crash rate etc) 

0:04:46            -> JS instrumentation -> JS pagetags are places on pages we want to monitor, and when users download the page, metadata is sent back which is used for monitoring 

0:04:59            -> device agents can be deployed to capture information about the behaviour of the apps 

0:05:00            -> we have web logs, network analysis, mobile SDK, JS injection and user device agents 


-----------------------------------------------
Video: End user monitoring instrumentation
-----------------------------------------------
Note Time:         Note Text:                     

0:00:37            -> riverbed -> capturing data for an example petclinic app. There is a steel central trial sign up, it's a website and he's made an account 

0:01:06            -> in an account, he's logged into the analytics UI -> it's a panel of different performance metrics. There is another tab with the web app which is in a container 

0:01:44            -> clicking on a different part of the webpage generates a request which is sent to the application, and the response is generated and returned -> we're looking at the mechanics of how the webpage works from the UI perspective 

0:02:16            -> inspecting the webpage in the console -> there is a network tab, and every time there is a change in the webpage (clicking on a new link), then there is a change in the network tab of the inspected webpage 

0:02:45            -> in the console -> you can see analytics have been generated and sent to the monitoring software. What is being sent is an image 

0:03:14            -> JS injection -> there is a change in the web application, and then a beacon is sent back to an analytics engine for monitoring 

0:03:51            -> the beacon returns metadata -> and back in the UI for steel central (the monitoring webpage with the analytics), the changes to the web application have been included as part of analytics 

0:04:23            -> there are multiple ways of adding tags to webpages for monitoring -> these can inject JS page tags into the response when the browser containing the web application is rendered 

0:05:26            -> there is a JS snippet on the steel central webpage which can be injected in the web application for monitoring -> you inject page tags onto the web application using JS snippets generated from monitoring software (which generates graphs for data science like interpretations) 

0:05:58            -> back in the inspected console for the web application -> the source can be inspected -> and it has the JS web tag from the monitoring software 

0:06:25            -> the user requests the webpage and then the tag sends a response back to the monitoring software when the web application works -> it's sending a token back 

0:07:16            -> navigation timing API -> browsers provide APIs which expose performance 


-----------------------------------------------
Video: End user monitoring in action
-----------------------------------------------
Note Time:         Note Text:                     

0:01:35            -> end user data -> he's logged into steel central and is on the homepage for the panel (under user experience). In the applications tab, there are analytics for the pet clinic tab with different graphs for performance metrics 

0:03:09            -> there is another tag with user location -> where the users were on the map who used the application <- if there are too many of them in a given location the servers in that region can become overloaded 

0:06:09            -> each session the webpage was used has a different tag -> we know which mac version and browser version the request came from. You can see which combinations of hardware and browser the web application works the worst and best on 


-----------------------------------------------
Video: System monitoring: See the box
-----------------------------------------------
Note Time:         Note Text:                     

0:01:23            -> monitoring statistics -> CPU, memory, disk and network 

0:01:35            -> system monitoring with CPU and memory graphs. These are important for hardware and system operation statistics. Load average, memory statistics -> system monitoring can give you information to draw conclusions from / to manage resources 

0:01:39            -> levels of statistics -> docker containers, virtual machines, hardware hosts 

0:02:13            -> system monitoring <- CPUs and memory graphs. This can help you figure out what is wrong with the service / for troubleshooting 

0:02:48            -> the core / other resources being tagged 

0:02:48            -> there are different levels you can test from (e.g from the system perspective and the instance which we're looking at). Graphs used to monitor systems can look different depending on the level we are monitoring at 

0:02:48            -> per process / container / VM metrics 

0:02:48            -> the bottleneck night not always be the server -> system monitoring can tell you where the bottleneck is -> CPU, memory, disk or network 

0:02:48            -> the meaning of different statistics -> load average, linux memory statistics etc 

0:03:22            -> linux memory management does a lot of virtual memory allocation so running out of memory is less of a problem -> the system can manage the memory. The processes it drops in hardware and use cases are logged 

0:03:22            -> being careful where averages are used (averages as well as maximums) 

0:04:04            -> metric monitoring is about usage (errors and transmits), and this is different to disk monitoring 

0:04:24            -> using the appropriate monitoring for the context -> you want to monitor something which indicates well what you want to know (rather than produces false positives and negatives) 


-----------------------------------------------
Video: System monitoring in action
-----------------------------------------------
Note Time:         Note Text:                     

0:00:00            -> there is a tab in chrome with the datadog website open 

0:00:00            -> an example setting up system monitoring on a web application using data dog 

0:01:21            -> he pastes the line of code into the terminal 

0:01:21            -> he installs datadog under integrations > agent > then under Amazon Linux, there is a line of code 

0:01:21            -> under the infrastructure tab, there is a list of the different monitoring with the name of the computers / servers 

0:03:58            -> sudo datadog-agent --help <- to ge usage 

0:03:58            -> status datadog-agent <- to verify if it's installed 

0:03:58            -> then sudo and he pastes in the line of code again -> and this installs the monitoring software/ agent data dog 

0:05:45            -> sudo datadog-agent status | more <- this returns the agent version and the checks the agent is running 

0:06:36            -> under monitors > manage monitors, there is one monitor setup by default. He adds another monitor -> they are virtual monitors. He selects a host monitor for the new host, there are several different configurations 

0:06:36            -> under integrations, there is a list of different integrations for datadog with various OS's. The documentation under integration contains information about the different statistics 

0:06:36            -> datadog has specific documentation -> help > resources > guides and references <- then there is documentation 

0:06:36            -> in an example, he's selected a graph for the number of nodes over a unit time, for the number of devices and a specific host 

0:06:36            -> you can zoom into the different graphs -> there is also a metrics explorer and you can choose which graph you want it to return (from the agent and the system) 

0:06:36            -> under infrastructure, the list is there -> which can be inspected for information about the server -> this is also returning information about the server (various graphs) 

0:06:36            -> then in the Chrome page for datadog, the service has started 

0:07:17            -> he sets up the monitor to email him is the server is not used for more than 2 minutes -> it's more like an alert system than a monitor. It's monitoring for the purpose of producing alerts in this example 


-----------------------------------------------
Video: Network monitoring
-----------------------------------------------
Note Time:         Note Text:                     

0:00:00            -> modern systems are interconnected -> network visibility allows these to be monitored. If something is not visible then it can't be monitored 

0:00:55            -> network monitoring and observability 

0:01:35            -> network monitoring -> getting visibility into the health of network monitoring devices <- knowing how well network monitoring devices work and how accurate they are as measures of a system's functioning 

0:02:09            -> SNMP -> simple network monitoring protocols 

0:02:33            -> rates, latency and errors <- monitoring these for all devices in a network to be able to identify where issues lie. Collaborating with networking teams to be able to do this (dev netOps) 

0:03:18            -> topology mapping -> mapping the network, and each node on the network has an address. We have packets (for monitoring and diagnostics, information about the client - these have payloads and header informations -> there are different methods of packet capturing) and flow analysis 

0:03:48            -> if we have monitoring information it doesn't necessarily tell us the cause -> it's a data science problem, and it also creates security concerns 

0:04:11            -> NetFlow -> a feature which collects IP network traffic / records of information between IPs on a network. For instance being able to see which parts of the network use the most resources / to imply an attack on the network 

0:04:33            -> Azure and AWS provide network monitoring 

0:04:53            -> there are options to collect packets -> you can use packet and flow monitoring for deep / broad monitoring 


-----------------------------------------------
Video: Software metrics: What's that doing?
-----------------------------------------------
Note Time:         Note Text:                     

0:00:13            -> there are different applications and modules for software monitoring <- metrics to monitor the performance etc of software -> this is not the same as monitoring the network. We are gathering information about what errors are there and others 

0:00:46            -> there is no standard metric for monitoring software -> it is software dependent. If you have to run an API to get metrics, if can add load to the system -> so we use external tools to monitor the performance of software 

0:01:23            -> there are tools for monitoring software which does specific tasks (e.g SQL database management, for various different types of software which do the same general tasks) 

0:01:51            -> if can be tricky to know which metrics to use -> there is documentation for add-ons 

0:02:21            -> getting the software the output metrics vis API / storage, and then running a statistics app in a container which sends the data to monitoring tools -> which produce graphs for the monitoring 


-----------------------------------------------
Video: Software metrics in action
-----------------------------------------------
Note Time:         Note Text:                     

0:00:35            -> he has a the datadog tab open and you can see the incoming data 

0:00:56            -> docker ps -a <- to see the status of the containers running which are linked to datadog (in the terminal) 

0:01:18            -> on the datadog tab -> infrastructure > containers <- you can see the currently running container and information about it 

0:02:27            -> under integrations, there are different extensions / integrations you can install for certain performance metrics. Under integrations > APIs, there are different API keys and application keys 

0:03:31            -> in the terminal, he's made a new file which he wants to send to datadog. He's added the file to a new txt file, and is 'posting' it to datadog via the terminal, linked with an API key 

0:04:13            -> in the datadog tab looking at the events stream, the new customer is there, which was sent from the terminal 

0:05:05            -> back in the terminal (he's logged into the server remotely via his computer), he's made another file to post to datadog, which will add to the metrics which it's recording 

0:06:09            -> back in datadog in Chrome, metrics > explorer > he's searched for the metric and there is a record of the file he sent from the terminal 


-----------------------------------------------
Video: Application monitoring
-----------------------------------------------
Note Time:         Note Text:                     

0:00:46            -> we won't know there app are failures if we don't monitor them <- it's not just about monitoring infrastructure 

0:01:58            -> app logic loss (untested scenarios causing loops), capacity constraints (different workloads on the resources which are too large), dependency failures (DNS lookups could be longer than expected, e.g) 

0:02:50            -> different metrics -> transaction throughput (rate of work done, completed requests per second), response (time per unit of work), error rate (amount of errors per artefact) 

0:03:33            -> not collecting too many metrics (only the relevant ones). Tracing is a detailed record of how a request is carried out by the application logic through every step of the system 

0:04:05            -> tracing data -> e.g a failed checkout request could be traced back to a failed SQL query. App monitoring software -> instrumentation agents and back end analytics 

0:04:37            -> instrumentation <- injecting track and call into the application at runtime and record how the application works -> then this is sent to backend analytics 

0:05:17            -> implementation -> tracking the most important metrics relevant to the problem, use the data and devops principles 


-----------------------------------------------
Video: Application monitoring in action
-----------------------------------------------
Note Time:         Note Text:                     

0:00:17            -> app performance analysis and monitoring techniques -> we're using a map example on a geographic monitoring system 

0:01:16            -> picking a timeframe and going to the instance tab for metrics. We're looking at graphs for different performance metrics -> this is the server response time for a JS application. Another one, exceptions - we have a graph exceptions vs time -> how many errors per series of time 

0:02:13            -> then we have the number of transactions which are being executed against time -> aggregate response time / exceptions. There is another tab with metrics only we care about 

0:03:15            -> server response time (the interactions with the server -> this implies how the app is being used). He has a panel with metrics for the petclinic app -> he's inspecting the slowest transaction time with the app 

0:03:55            -> in the instance where the app has the longest transaction time, we can see the biggest causes of delays in the transaction time -> so we know what to optimise. It's like data science on the performance of the software 

0:04:15            -> it's showing different methods which are recorded in the transaction trace -> and inspecting the longest ones 

0:05:06            -> there is another series of metrics for the call stack -> he's looking around for areas which had call times above average 

0:05:32            -> another one is exception monitoring -> why are we getting specific exceptions etc 

0:07:00            -> application topology maps -> global application dependencies / bottlenecks. He's looking at which transactions were happening (in the petclinic container, or from a server) -> monitoring tools can be used to look at where / what servers the transactions happen on for given apps 

0:07:46            -> he's chosen another example, and we're looking at the instance CPU (another metric, against the time axis) -> it's data science on apps, we're making conclusions about the performance of the software based off of the metrics 

0:07:57            -> data science is similar to experimental Physics -> interpreting the graphs 

0:08:49            -> memory use and transaction tracing are other examples - and interpreting can give us information about how to take action / do diagnostics / creating alerts  


-----------------------------------------------
Video: Log monitoring
-----------------------------------------------
Note Time:         Note Text:                     

0:00:32            -> log monitoring -> logging events (rather than metrics). Events carry more information and can be turned into metrics (e.g counting the number of events) 

0:01:26            -> logs can contain information about why something has happened and are formatted in json and others, which can allow the log to be structured 

0:02:06            -> logs have to be moved to a server to be searched -> and moving them to logging products can cost depending on which is used. Elcstack is the most common 

0:02:52            -> Splunk, Sumo Logic etc he's listing all of the different logging tools -> some are for security event managers with certain use cases 

0:03:47            -> logging well -> putting people in contact with their own logs to improve knowledge about functioning of the systems and software. They recommend syslog log levels and log4j log levels -> choosing too many logs can be over engineering 

0:04:11            -> logging and rotation of log files is important 

0:04:46            -> log rotate to delete old logs can be used to manage log files. Timestamps are also commonly used -> with function names and variables 


-----------------------------------------------
Video: Log monitoring in action
-----------------------------------------------
Note Time:         Note Text:                     

0:00:03            -> drawbacks of log data -> the quantity of it, and cost. It can contain sensitive information which might need masking and require certain logging systems to meet privacy needs 

0:00:22            -> splunk software -> he has an example tab in Chrome 

0:01:21            -> he's gone into universal forwarder and followed the instructions. Search and reporting > * > and looking at the logs > searching errors. He is inspecting the different error logs 

0:01:43            -> searching through error logs in an engine on splunk 

0:02:38            -> there is a patterns tab <- this processes log files and tries to find commonalities 

0:05:05            -> in the terminal, he removes the stock containers which are benign on the log. He's gone back to the pet clinic app > find owners, and searched for an owner in the database -> back in the tab with splunk, it's logged the activity for the search and it didn't work (he deliberately searched for a user which didn't exist) 


***********************************************
Chapter: 3. Monitoring Technique
***********************************************


-----------------------------------------------
Video: Implementing monitoring
-----------------------------------------------
Note Time:         Note Text:                     

0:01:30            -> implementing monitoring -> people first. The skills and culture to build a monitoring practice <- a culture of monitoring, systemic curiosity (how applications work, not would / should / could work), being analytically rigorous and open 

0:02:07            -> a common problem is -> apps and systems are ready, one person does the monitoring > they get overwhelmed as the system scales, then they leave with the knowledge of how the monitoring works with them. It's important to de-centralise the monitoring system 

0:03:47            -> building the monitoring system so it's self-service. Having a unanimously agreed system of monitoring and performance analytics. Discussing what is actionable -> which error messages call for major action and which don't 

0:04:16            -> instrumentation points being layered with different iterations -> synthetic monitors for every service, then monitoring logs and application workload / transactions. Using software metrics isn't as important as these types of information (they argue) 

0:04:26            -> demand, applications and resources 

0:04:46            -> considering the user experience. People > process > tools 


-----------------------------------------------
Video: Using monitors: Visualization
-----------------------------------------------
Note Time:         Note Text:                     

0:00:15            -> using monitoring data -> graphs and alerts 

0:01:15            -> visualisation - graphs aren't always the best way of making conclusions (sometimes we want to detect issues, plan, etc - we need to consider who the monitoring will benefit and what we are trying to show). Problem detection needs very simple visual representations (on dashboards) 

0:01:37            -> considering which metrics need looking in context to each other (using data in conjunction to draw conclusions) 

0:01:50            -> needing there to be enough data (or risking missing conclusions) 

0:01:50            -> needing there to be enough data (or risking missing conclusions) 

0:02:18            -> for business, metrics can be used which state which actions need to be taken -> these can be embedded into the systems 

0:02:56            -> monitoring tools can create reports. Sometimes there is a need to track performance for regulations 

0:03:17            -> monitoring data can suggest which areas need improvements 

0:04:21            -> diagrams need to be concise and understandable (rather than only understandable to the people who are making the monitoring system) 


-----------------------------------------------
Video: Using monitors: Alerting
-----------------------------------------------
Note Time:         Note Text:                     

0:00:27            -> you need to use data to take action -> this is the purpose of alerts 

0:00:40            -> who is a given alert for, and why? 

0:01:55            -> email / text etc to developers, or chatrooms for events etc -> you need to minimise false negatives and positives (you want to be alerted when something is wrong, not when nothing is wrong or something is wrong and was missed). Not alerting too much -> alerting too much causes people not to pay attention to them (and so not take action on them) 

0:03:13            -> you want monitors to be actionable -> rather than encouraging complacency 

0:04:51            -> test the alert by feeding data into the monitor, monitor the right metric, send as much information with the alert to the operator to reduce guesswork (this includes suggested actions), have a feedback loop for alerts which are missed or where they should have happened, measure the quality of the events being logged for alerts 


-----------------------------------------------
Video: Monitoring challenges
-----------------------------------------------
Note Time:         Note Text:                     

0:00:14            -> the system, human and tools obstacles 

0:01:21            -> systems -> their growing complexity means they are harder to monitor (scaling / automation, it has to be lightweight). Monitoring came as an afterthought -> the importance of observability 

0:02:04            -> when monitoring is used to blame people for failures vs to fix the failures <- monitoring in a social context. Errors and expecting other people to fix them -> group responsibility 

0:02:51            -> monitoring data objectively. Tool hugging -> people become too attached to a certain method of monitoring and don't want to change it 

0:03:17            -> cost - building or buying parts of the pipeline for monitoring <- using tools for integration for API 

0:04:19            -> there are different forms of overhead cost -> latency, the cost of doing monitoring (5% is a point to become concerned) 

0:05:01            -> who made the tools / what their interests are -> not feature lists, but your use cases. Data quality vs widgets -> if the underlying data is poor, the observability is limited (no matter how well graphs and reports are formatted) 

0:05:07            -> CAMS <- culture, automation, measurement, share 


***********************************************
Chapter: Conclusion
***********************************************


-----------------------------------------------
Video: Next steps
-----------------------------------------------
Note Time:         Note Text:                     

0:00:00            -> systems, humans and tools   

0:01:20            -> more resources -> monitoring weekly newsletter, practical monitoring book, the art of monitoring book, tech conferences (velocity), monitorana conference 

0:01:53            -> using the right metrics and having visualisations for them. Too many graphs / alerts -> lack of clarity 

